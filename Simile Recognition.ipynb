{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab32a6f3-ca2a-4489-a70c-f069fa4bc4a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/xumingkai/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/xumingkai/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import csv\n",
    "import nltk\n",
    "import openai\n",
    "import pandas as pd\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# OpenAI API setup\n",
    "openai.api_key = 'X'\n",
    "MODEL = \"gpt-3.5-turbo\"\n",
    "\n",
    "# Function to clean and tokenize text\n",
    "def clean_and_tokenize(text):\n",
    "    text = re.sub(r'\\s+', ' ', text)  \n",
    "    text = text.lower()\n",
    "    sentences = sent_tokenize(text)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    processed_sentences = []\n",
    "\n",
    "    for sentence in sentences:\n",
    "        words = word_tokenize(sentence)\n",
    "        lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "        processed_sentences.append((sentence, lemmatized_words))\n",
    "\n",
    "    return processed_sentences\n",
    "\n",
    "def filter_potential_similes(sentences):\n",
    "    simile_sentences = []\n",
    "    for sentence, words in sentences:\n",
    "        if \"like\" in words or (\"as\" in words and \"as\" in words[words.index(\"as\")+1:]):\n",
    "            simile_sentences.append(sentence)\n",
    "    return simile_sentences\n",
    "\n",
    "# Setting your OpenAI API key\n",
    "openai.api_key = 'sk-proj-SZiOR5j3WnDOBpZTaVxaT3BlbkFJbXg5hwCFmRo9K5607sSI'\n",
    "MODEL = \"gpt-3.5-turbo\"  # Choose the model according to your account\n",
    "\n",
    "# Function to check if given sentences are similes\n",
    "def check_if_simile(sentences):\n",
    "    \"\"\"Check if given sentences contain similes and return a list of sentences that are similes.\"\"\"\n",
    "    similes = []\n",
    "    prompt = (\n",
    "        \"Act as a computational linguist, Your task is to determine whether a given sentence contains a simile. \"\n",
    "        \"A simile is a figure of speech that directly compares two different things, \"\n",
    "        \"typically using words such as 'like' or 'as...as...'. Review the sentence provided \"\n",
    "        \"and respond with 'Yes' if it contains a simile, or 'No' if it does not.\"\n",
    "    )\n",
    "    for sentence in sentences:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": prompt},\n",
    "                {\"role\": \"user\", \"content\": sentence}\n",
    "            ],\n",
    "            max_tokens=10,  # Adjust max_tokens to a smaller number if only \"Yes\" or \"No\" is needed\n",
    "            temperature=0.5\n",
    "        )\n",
    "        if \"yes\" in response.choices[0].message['content'].lower():\n",
    "            similes.append(sentence)\n",
    "    return similes\n",
    "\n",
    "# Function to extract elements of similes\n",
    "\n",
    "def extract_elements(similes):\n",
    "    \"\"\"Extract tenor, vehicle, and shared property from simile sentences\"\"\"\n",
    "    elements = []\n",
    "    system_prompt = (\n",
    "        \"Act as a computational linguist and identify the core elements of a simile.\"\n",
    "        \"The tenor is the primary subject of the simile, which is being described.It is the part of the simile that is being described or compared to something else to convey meaning\"\n",
    "        \"The vehicle is the image or concept used to make the comparison.\"\n",
    "        \"The shared property is the characteristic or quality that is common to both the tenor and the vehicle\"\n",
    "        \"Identify the tenor, the vehicle (object of comparison), and the shared property if explicitly mentioned. \"\n",
    "        \"Use one word in the sentence for each element.\"\n",
    "    )\n",
    "    \n",
    "    for simile in similes:\n",
    "        user_prompt = f\"Given the sentence, identify the tenor and vehicle. Provide your response clearly and concisely:\\n\\n'{simile}'\"\n",
    "        \n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            max_tokens=60,\n",
    "            temperature=0.5\n",
    "        )\n",
    "        \n",
    "        text = response.choices[0].message['content']\n",
    "        \n",
    "        # Using regular expressions to match single-word responses for tenor and vehicle\n",
    "        tenor_match = re.search(r\"Tenor:\\s*(\\S.*)\\s*\", text)\n",
    "        vehicle_match = re.search(r\"Vehicle:\\s*(\\S.*)\\s*\", text)\n",
    "        property_match = re.search(r\"Shared property:\\s*(\\S.*)\\s*\", text)\n",
    "        \n",
    "        tenor = tenor_match.group(1) if tenor_match else \"\"\n",
    "        vehicle = vehicle_match.group(1) if vehicle_match else \"\"\n",
    "        shared_property = property_match.group(1) if property_match and property_match.group(1) else \"\"\n",
    "        \n",
    "        elements.append((simile, tenor, vehicle, shared_property))\n",
    "    \n",
    "    return elements\n",
    "\n",
    "def get_core_word(phrase):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Act as a computational linguist. When provided a phrase, respond with only the core word of the phrase and nothing else.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Extract the core word from the phrase: '{phrase}'\"}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    core_word = response['choices'][0]['message']['content'].strip()\n",
    "    core_word = re.sub(r\"['\\\"]\", \"\", core_word).lower()\n",
    "    return core_word\n",
    "\n",
    "# Function to process a single book\n",
    "def process_book(file_path):\n",
    "    rank, book_name = os.path.basename(file_path).split('_', 1)\n",
    "    book_name = book_name.replace('.txt', '').strip()\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "        processed_sentences = clean_and_tokenize(content)\n",
    "        potential_similes = filter_potential_similes(processed_sentences)\n",
    "        confirmed_similes = check_if_simile(potential_similes)\n",
    "        simile_elements = extract_elements(confirmed_similes)\n",
    "        data = []\n",
    "        for simile, tenor, vehicle, shared_property in simile_elements:\n",
    "            data.append([rank, book_name, simile, tenor, vehicle, shared_property])\n",
    "    \n",
    "    # Convert data to DataFrame\n",
    "    df_output = pd.DataFrame(data, columns=['Rank', 'Book Name', 'Simile', 'Tenor', 'Vehicle', 'Shared Property'])\n",
    "    \n",
    "    # Apply get_core_word to ensure each element is a single word\n",
    "    for column in ['Tenor', 'Vehicle', 'Shared Property']:\n",
    "        df_output[column] = df_output[column].apply(lambda x: get_core_word(x) if len(x.split()) > 1 else x)\n",
    "    \n",
    "    return df_output\n",
    "\n",
    "# Function to save DataFrame to CSV\n",
    "def save_to_csv(df, output_file):\n",
    "    df.to_csv(output_file, index=False, encoding='utf-8')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9a17c162-504b-496b-9196-fa56d4056637",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"corpus/100_Incidents in the Life of a Slave Girl, Written by Herself.txt\"\n",
    "output_file = \"100.csv\"\n",
    "df_output = process_book(file_path)\n",
    "save_to_csv(df_output, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f696c7-ffb7-4f65-97f0-e41f671f3b29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
